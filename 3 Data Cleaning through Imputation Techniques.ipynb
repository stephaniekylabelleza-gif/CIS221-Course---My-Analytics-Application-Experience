{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89816221-acef-42a2-a0c8-b06653916fe3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <font face = 'Impact' color = '#FFAEBC' > Data cleaning through imputation techniques <font/>\n",
    "#### <font face = 'Times New Roman' color = '#B5E5CF'> License: GPL v3.0<font/>\n",
    "#### <font face = 'Times New Roman' color = '#B5E5CF'> Author and Trainer: Paolo Hilado MSc. (Data Science)<font/>\n",
    "This notebook provides a practical introduction to handling missing data through various imputation techniques. You'll explore methods such as mean, median, and mode imputation, as well as forward/backward fill, group-wise strategies, and a brief look at more advanced approaches like interpolation and model-based imputation. The goal is to equip you with the tools to clean and prepare datasets effectively for analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bebcc-f6d0-41fb-8636-6b49240711a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import researchpy as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c4cb7-895e-4313-9c05-dfe3210179b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"PracticeTest.xlsx\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13102444-8e83-4409-b8a7-70c9e26c47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for NAs or missing cases\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7891f5-e5ff-4436-9d4d-2e8762c31cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For curiosity, you may subset the dataframe to include all rows that is made up of all missing cases and view them.\n",
    "missing_df1= df[df.isnull().all(axis=1)] # take a subset to include all rows with missing cases\n",
    "missing_df2= df[df.isnull().any(axis=1)] # take a subset to include any row with missing cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef20746-e496-49b2-bb3e-fda01a9f9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25ae35-1a8b-46b4-9628-20671f2a09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15654152-87b6-4348-80db-5729942b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371d272-0ca7-4807-b216-b87ef79e2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the descriptive analysis results using .describe() which excludes missing cases.\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0277577-f1f5-416e-9759-44fcf30218ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the columns in the data frame that have missing cases.\n",
    "missing_columns = df.isnull().sum()\n",
    "# Show only columns with at least one missing value\n",
    "# missing_columns = missing_columns[missing_columns > 0]\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4fe2e-0716-4408-aba2-5242badef3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3d783-3ede-4aab-a332-38fb7c811760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:,1:31]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152f3ab-ac53-4f68-a5e1-e7f2321db40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing mean imputation\n",
    "# Check out the mean for each feature\n",
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6b63b-b854-446c-be6c-77af0a14fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d369bd-cc59-4a4a-ac8e-f17654acf5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform mean imputation for each column in your dataframe \n",
    "df1.fillna(np.round(df1.mean(),2), inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30a35b-0780-4863-8349-0c178c7d365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e1f7e-1fe8-4c93-b192-cc350834cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3399d4-047a-4d63-b4cf-a20389a21ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"PracticeTest.xlsx\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82113338-f940-4cae-a4e3-2a6ac7307704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:,1:31]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e97ef5-1074-4f20-9daa-312125ca40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing median imputation\n",
    "# Check out the median for each feature\n",
    "df1.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce5f6f-47f1-4ba0-88ef-3a73faf71dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform median imputation for each column in your dataframe\n",
    "df1.fillna(df1.median(), inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76737e-a84a-42e4-9ab2-bb6ca2f219c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"PracticeTest.xlsx\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba893c7-0d35-487e-813b-7dca4b1b9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the frequently occuring observation for variable Sex\n",
    "df['Sex'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c696e-6659-4f41-a812-ea26513174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform mode imputation for column Sex\n",
    "df['Sex'] = df['Sex'].fillna(df['Sex'].mode()[0])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b896681-29b4-427c-a662-3e16460a0993",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "source": [
    "# <font color = '#FFAEBC' > Remember that these basic data imputation techniques should be used with caution and avoided as much as possible. <font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6849b9c-28b8-4606-a1b6-3e733489184a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "# <font color = '#FFAEBC' > It is always of best practice to verify with the primary source and input the accurate data. When the missing value can be computed using existing features from the data frame, this is also a good alternative. <font/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
